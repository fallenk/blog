---
title: åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ è®ºæ–‡
date: 2019-08-29 23:22:15
tags: [paper]
category: [è®ºæ–‡é˜…è¯»]
---

è™½è¯´å…·ä½“è¦åšçš„ä¸œè¥¿ç›®å‰è¿˜åœ¨æ€è€ƒæ¯”è¾ƒå¤šï¼Œä»ä¹‹å‰çš„ [ã€æ•´ç†ä¸€ä¸‹çœ‹è¿‡çš„è®ºæ–‡ã€‘](http://jcf94.com/2017/08/18/2017-08-18-paper/) é‡Œé¢æŠŠç›¸å…³çš„è®ºæ–‡ç†å‡ºæ¥äº†ã€‚

<!--more-->

å¤§è‡´åˆ†æˆä¸‰ä¸ªæ–¹é¢ï¼š

- Distributed Machine Learning System
- Distributed Deep Learning System
- Large Scale Neural Network Training

è™½è¯´é‡ç‚¹ä¸»è¦é›†ä¸­åœ¨åé¢ä¸¤å—ä¸Šï¼Œä¸è¿‡å…¶ä»–æ–¹é¢çš„æœºå™¨å­¦ä¹ æ¯•ç«Ÿå‘å±•çš„æ—¶é—´æ¯”æ·±åº¦å­¦ä¹ æ›´æ—©ï¼Œåˆ†å¸ƒå¼ç³»ç»Ÿæ–¹é¢è¿˜æ˜¯æœ‰å‚è€ƒä»·å€¼çš„ã€‚

æŠŠç¬¬äºŒä¸‰ä¸¤éƒ¨åˆ†åˆ†å¼€æ•´ç†ä¸»è¦è€ƒè™‘ä¸€ä¸ªæ˜¯åæ¡†æ¶å’Œç®—æ³•è®¾è®¡ï¼Œä¸€ä¸ªæ˜¯åå‘é’ˆå¯¹æŸä¸ªå…·ä½“çš„åº”ç”¨é—®é¢˜åšçš„å¤§è§„æ¨¡å®ç°ã€‚



# Distributed Machine Learning System

## 2013 NIPS - More Effective Distributed ML via a Stale Synchronous Parallel Parameter Server

> è¯è¯´æˆ‘ç¬¬ä¸€çœ¼çœ‹è¿™ä¸ªç³»åˆ—çš„æ–‡ç« è¿˜ä»¥ä¸ºè®²çš„å°±æ˜¯æ·±åº¦å­¦ä¹ äº†ï¼Œåæ¥æ‰å‘ç°è¿™äº›å…¨æ˜¯ä¸»è¦é’ˆå¯¹æœºå™¨å­¦ä¹ çš„ã€‚

åˆ†å¸ƒå¼æ–¹æ³•è¿˜æ˜¯ä¸»è¦åŸºäºä¼ ç»Ÿçš„ Parameter Server å¯¹ Worker çš„å½¢å¼ï¼Œä½†æ˜¯æå‡ºäº†ä¸€ç§ SSP(Stale Synchronous Parallel) æ¨¡å‹æ¥è§£å†³æ™®é€šçš„åŒæ­¥æˆ–è€…å¼‚æ­¥æ¨¡å¼ä¸‹è®­ç»ƒä¼šæœ‰çš„é—®é¢˜ã€‚SSP æ¨¡å‹å¤§è‡´æ˜¯è¯´ä¼šåœ¨æœ¬åœ°ç»´æŠ¤ä¸€ä¸ªå‚æ•°çš„ cacheï¼Œæ¯ä¸ªå·¥ä½œçš„ node ç›´æ¥ä»æœ¬åœ°çš„ cache ä¸­æ‹¿æ•°æ®ï¼Œè·Ÿ PS ä¹‹é—´çš„åŒæ­¥é—®é¢˜åº”è¯¥æ˜¯å¦å¤–å¤„ç†ï¼Œè¿™æ ·å°±æŠŠæ¯ä¸ªå·¥ä½œ node ç­‰å¾…ç½‘ç»œçš„æ—¶é—´ç»™é™ä¸‹æ¥äº†ã€‚

Introduction ä¸­é¦–å…ˆåˆ†æäº†æœºå™¨å­¦ä¹ è®­ç»ƒä¸­å¯èƒ½æœ‰çš„é—®é¢˜ï¼šmassive data volume å’Œ massive model sizeï¼Œæ•°æ®é‡å¤ªå¤§å’Œæ¨¡å‹å¤ªå¤§è¿™ä¸¤ä¸ªé—®é¢˜å³ä½¿å¯ä»¥é€šè¿‡å°½å¯èƒ½åœ°ç¼©å‡ã€å‹ç¼©ï¼Œä¹Ÿç»ˆæœ‰ä¸ªå°½å¤´ï¼Œæœªæ¥æ€»æœ‰è§£å†³ä¸äº†çš„æ—¶å€™ï¼Œå› æ­¤ä¸å¾—ä¸éœ€è¦ç”¨åˆ°åˆ†å¸ƒå¼çš„è®­ç»ƒç¯å¢ƒã€‚

åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ç³»ç»Ÿéœ€è¦è§£å†³çš„æœ€ç»ˆç›®æ ‡æ˜¯ï¼š

1. æœ€å¤§åŒ–åˆ©ç”¨è®¡ç®—èµ„æºï¼ˆæŠŠæ›´å¤šçš„æ—¶é—´èŠ±åœ¨è¿ç®—ä¸Šï¼‰
2. è®­ç»ƒå®Œä¹‹åè¦èƒ½æ”¯æŒ inference
3. ä¿è¯æ­£ç¡®æ€§ï¼ˆä¿è¯åˆ†å¸ƒå¼ä¹‹åç½‘ç»œä»ç„¶æ˜¯èƒ½å¤Ÿæ”¶æ•›çš„ï¼‰

æ–‡ä¸­å¯¹ PS çš„å®šä¹‰æ˜¯ï¼šä¸€ä¸ª**å…±äº«çš„é”®å€¼å¯¹**å­˜å‚¨æ¨¡å‹ï¼ŒåŒæ—¶è¦å…·å¤‡**è¯»å–å’Œæ›´æ–°**å‚æ•°çš„åŒæ­¥æœºåˆ¶ã€‚å…±äº«çš„é”®å€¼å¯¹å­˜å‚¨æ–¹å¼èƒ½ç®€åŒ–ç¼–ç¨‹å¤æ‚åº¦ï¼Œæ•°æ®åŒæ­¥æ˜¯ä¸ºäº†ä¿è¯æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„æ­£ç¡®æ€§ã€‚

SSP è¿™ç§æ¨¡å‹çš„é‡ç‚¹åœ¨äºåƒå‰é¢è¯´çš„æœ¬åœ°ä¿ç•™å°½å¯èƒ½æ–°çš„æ—§å‚æ•°ï¼Œè¿™é‡Œç»™äº†ä¸ªå¾®è½¯ä¸€ç¯‡æŠ€æœ¯æŠ¥å‘Šçš„å¼•ç”¨ï¼š

- [Replicated Data Consistency Explained Through Baseball](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/10/ConsistencyAndBaseballReport.pdf)

å¦‚æœè¯´åŒæ­¥å¯ä»¥è¾¾åˆ°æ›´å¥½çš„ qualityï¼Œå¼‚æ­¥å¯ä»¥è¾¾åˆ°æ›´å¥½çš„ quantity çš„è¯ï¼ŒSSP æ˜¯å–äº†è¿™ä¸¤ç§æ–¹æ¡ˆçš„æŠ˜ä¸­ï¼Œæœ€ç»ˆæ¯”è¿™ä¸¤ç§éƒ½è¦æœ‰æ•ˆã€‚

------

è§„å®šæ¯ä¸ª worker è¿è¡Œæ—¶æœ‰ä¸ª clock è®¡æ•°å™¨ï¼ˆæ—¶é—´æˆ³ï¼‰ï¼Œè®°çš„æ˜¯å½“å‰åˆ°äº†ç¬¬å‡ è½®è¿­ä»£ã€‚ç»™å®šä¸€ä¸ªé˜ˆå€¼ sï¼ŒSSP æ¨¡å‹éµå¾ªä»¥ä¸‹å‡ ä¸ªè§„åˆ™ï¼š

- æœ€æ…¢çš„å’Œæœ€å¿«çš„ worker ä¹‹é—´è·‘çš„å‚æ•°ä¹‹é—´çš„ clock å·®ä¸èƒ½è¶…è¿‡ sï¼Œå¦åˆ™æœ€å¿«çš„ worker å°±è¦å¼ºåˆ¶ç­‰å¾…åé¢è¾ƒæ…¢çš„ worker ç®—å®Œäº†èµ¶ä¸Šæ¥
- å½“ä¸€ä¸ªå½“å‰ clock å€¼æ˜¯ c çš„ worker æäº¤ä¸€ä¸ªå‚æ•°æ›´æ–°æ—¶ï¼Œé‚£ä¸ªæ›´æ–°çš„æ—¶é—´æˆ³ä¸º c
- å½“ä¸€ä¸ªå½“å‰ clock å€¼æ˜¯ c çš„ worker è¯»å–å‚æ•°æ—¶ï¼Œæ ¹æ®ä¸Šè¿°è§„åˆ™ï¼Œå®ƒè¯»å–åˆ°çš„æ›´æ–°è‡³å°‘ä¼šåŒ…å« c-s-1 æ—¶é—´æˆ³ä¹‹å‰çš„æ‰€æœ‰æ›´æ–°å†…å®¹
- ä¸€ä¸ª worker è¯»å–åˆ°çš„**æ›´æ–°**æ€»ä¼šæ¯”å®ƒè‡ªå·±äº§ç”Ÿçš„æ‰€æœ‰ç»“æœ**æ›´æ–°**

> äº‹å®ä¸Šä½œè€…ç”¨ c å’Œ s è¿™ä¸¤ä¸ªå®šä¹‰å°±æŠŠ BSP å’Œå¼‚æ­¥ç»™æ€»ç»“åˆ°ä¸€èµ·äº†ã€‚å¦‚æœ s ä¸º 0ï¼Œç›¸å½“äºæ‰€æœ‰çš„ worker éƒ½æ˜¯å®Œå…¨åŒæ­¥çš„ï¼Œå½“ s æ˜¯æ— ç©·å¤§çš„æ—¶å€™ï¼Œå°±æ˜¯å®Œå…¨å¼‚æ­¥çš„ã€‚
>
> è¿™ä¸ª s å°±æ˜¯ SSP æ¨¡å‹ä¸­éœ€è¦ overlap çš„éƒ¨åˆ†ï¼Œs å¤ªå°åˆ™å¯èƒ½ç»å¸¸æœ‰äº› worker éœ€è¦ç­‰å¾…ï¼Œå¹¶è¡Œæ€§æä¸ä¸Šå»ï¼Œs å¤ªå¤§å½±å“é—®é¢˜æ•´ä½“çš„æ”¶æ•›ç‡ã€‚

------

å…·ä½“å®ç°ä¸Šï¼Œä½œè€…ç”¨äº†ä¸€ä¸ªç±»ä¼¼ cache é¡µè¡¨çš„ SSP tableï¼Œæ€æƒ³å¤§è‡´ä¹Ÿæ˜¯ç±»ä¼¼çš„ã€‚åœ¨å¤šä¸ª worker è·‘åœ¨å•ä¸ªèŠ‚ç‚¹ä¸­çš„æƒ…å†µä¸‹ï¼ŒèŠ‚ç‚¹å†…è¿˜å¯ä»¥å†å¤šåšä¸€å±‚çº¿ç¨‹é—´çš„æ•°æ® cacheã€‚

## 2014 ATC - Exploiting bounded staleness to speedup Big Data analytics

è¿™ç¯‡ paper çš„å†…å®¹æ˜¯ä¸Šé¢é‚£ç¯‡çš„åç»­ç ”ç©¶ï¼ˆè¯è¯´ä½œè€…éƒ½å·®ä¸å¤šï¼‰ï¼Œå¤§ä½“ä¸Šæ˜¯å¯¹ä¸Šç¯‡å†…å®¹ä½œäº†æ›´å¤šçš„è¡¥å……å’Œæå‡ã€‚ä½œè€…åœ¨å®éªŒä¸­å‘ç°åº”ç”¨äº† bounded staleness æ€æƒ³çš„ BSP æ¨¡å‹åˆ°æœ€åæ•ˆæœè·Ÿ SSP æ˜¯å·®ä¸å¤šçš„ï¼Œå› æ­¤å¯¹è¿™å…¶ä¸­çš„è¯¦ç»†æƒ…å†µå’ŒåŸå› ä¹Ÿä½œäº†æ·±å…¥åˆ†æã€‚

å¼•å…¥ bounded staleness æ€æƒ³çš„ BSP æ¨¡å‹è¿™é‡Œæˆä¸º A-BSPï¼ŒBSP æ˜¯æ¯æ¬¡è¿­ä»£ä¹‹åä¸€ä¸ªå¤§åŒæ­¥ï¼ŒA-BSP å°±æ˜¯æŠŠè¿™ä¸ªé™åˆ¶æ”¾å¼€ç‚¹ï¼Œæ¯ n æ¬¡è¿­ä»£ä¹‹åä¸€ä¸ªå¤§åŒæ­¥ã€‚ç”¨ä¸Šé¢ä¸€ç¯‡æè¿‡çš„å½’çº³æ–¹å¼ï¼ŒBSPã€A-BSPã€SSP éƒ½å¯ä»¥å½’åˆ°ä¸€èµ·ã€‚

SSP è¯´èµ·æ¥ç¡®å®æœ‰ç‚¹åƒæ˜¯åœ¨ A-BSP çš„åŸºç¡€ä¸Šåšä¸ªæµæ°´çº¿çš„æ„Ÿè§‰ã€‚å½“æ•´ä¸ªåˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œå„ä¸ªçº¿ç¨‹åšçš„ä»»åŠ¡ä¸å¤ªå¹³è¡¡ï¼Œæœ‰æ˜æ˜¾è¾ƒæ…¢çš„ worker å­˜åœ¨æ—¶ï¼ŒSSP èƒ½æ›´å¥½åœ°æé«˜å¹¶è¡Œåº¦ï¼ˆè´Ÿè½½å‡è¡¡ï¼Ÿï¼‰ã€‚ä½† SSP ç›¸å¯¹ A-BSP çš„é€šä¿¡æ¬¡æ•°æ˜¯æ›´å¤šçš„ï¼Œå½“å„ä¸ª worker çš„è¿è¡Œé€Ÿåº¦å·®è·å¾ˆå°æ—¶ï¼Œå¯èƒ½ç”¨ A-BSP ä¼šæœ‰æ›´å¥½çš„æ•ˆæœã€‚

è¿™é‡Œç”¨æ¥ç»´æŠ¤æ•°æ® cache çš„æ•°æ®ç»“æ„å« LazyTableï¼Œå…¶å®å°±æ˜¯å‰é¢ SSP Table çš„å‡çº§ç‰ˆï¼Œå®ç°å¤§è‡´éƒ½æ˜¯ç±»ä¼¼çš„ã€‚

å¦å¤–è¿™é‡Œè¿˜åšäº†é¢„å–å’Œå®¹é”™ã€‚

## 2014 SoCC - Exploiting Iterative-ness for Parallel ML Computations

To be read.

## 2014 OSDI - Scaling distributed machine learning with the parameter server

To be read.

## 2015 - Distributed Machine Learning via Sufficient Factor Broadcasting

SFBã€‚

To be read.

## 2015 - Efficient Machine Learning for Big Data: A Review

æœºå™¨å­¦ä¹ ä¸å¤§æ•°æ®ç»“åˆæ–¹é¢çš„ä¸€ç¯‡ç»¼è¿°ã€‚

To be read.

## 2015 - Petuum: A new Platform for Distributed Machine Learning on Big Data

ä¸€ç§åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ çš„å¹³å°è®¾è®¡ã€‚

To be read.

## 2015 EuroSys - Malt: distributed data-parallelism for existing ml applications

ä¸€ä¸ªå« Malt çš„åº“ï¼Œç”¨äºæŠŠå¸¸ç”¨çš„æœºå™¨å­¦ä¹ åº”ç”¨ä»å•æœºæ”¹é€ æˆåˆ†å¸ƒå¼çš„ã€‚

To be read.

## 2015 SoCC - Managed Communication and Consistency for Fast Data-Parallel Iterative Analytics

ä¸€å¥—å« Bosen çš„åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ç³»ç»Ÿã€‚

To be read.

## 2016 EuroSys - STRADS: A Distributed Framework for Scheduled Model Parallel Machine Learning.

To be read.

## 2016 UAI - Lighter-Communication Distributed Machine Learning via Sufficient Factor Broadcasting

SFBã€‚

To be read.

## 2017 - Machine learning on big data Opportunities and challenges

To be read.

------

# Distributed Deep Learning System

## å…¶ä»–èµ„æ–™

- [ã€çŸ¥ä¹ä¸“æ  - ML@Scaleã€‘](https://zhuanlan.zhihu.com/mlscale)

## 2012 NIPS - Large Scale Distributed Deep Networks

Google çš„ç¬¬ä¸€ä»£æ·±åº¦å­¦ä¹ ç³»ç»Ÿ Distbeliefï¼Œç”± Jeffrey Dean å¤§ä½¬å¸¦å¤´ï¼Œå…¶å®æ˜¯ TensorFlow çš„å‰èº«ã€‚

ç°åœ¨è¯´çš„æ·±åº¦ç¥ç»ç½‘ç»œæœ€åˆçš„æ¥æºå°±æ˜¯ä¼ ç»Ÿæœºå™¨å­¦ä¹ é‡Œé¢çš„**å—é™ç»å°”å…¹æ›¼æœºï¼ˆRestricted Boltzmann Machineï¼ŒRBMï¼‰**ä»¥åŠ**å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMultilayer Perceptronï¼ŒMLPï¼‰**ç­‰ç­‰æƒ³æ³•ï¼Œè¿™ä¿©æ¼”å˜å‡ºæ¥äº†ä¸€ä¸ªå«**æ·±åº¦ä¿¡å¿µç½‘ç»œï¼ˆDeep Belief Networkï¼ŒDBNï¼‰**çš„ä¸œè¥¿ï¼ŒåŸºæœ¬è·Ÿä»Šå¤©çš„ DNN å·²ç»å¾ˆåƒäº†ã€‚Distbelief é‡Œé¢çš„ Belief æŒ‡çš„åº”è¯¥å°±æ˜¯ DBN å§ã€‚

å‡ºå‘ç‚¹åŸºæœ¬è·Ÿåæ¥çš„æ–‡ç« å¤§åŒå°å¼‚ï¼Œæ–‡ç« çš„é‡ç‚¹åœ¨äºï¼š

1. Downpour SGDï¼šå‰é¢è¿™ä¸ªå•è¯æ˜¯æè¿°å€¾ç›†å¤§é›¨çš„ï¼Œä¸çŸ¥é“æ•´ä¸ªè¯ç»„åº”è¯¥æ€ä¹ˆç¿»è¯‘æ¯”è¾ƒå¥½ï¼›
2. åŸºäº Sandblaster æ¡†æ¶å®ç°äº†ä¸€ä¸ª L-BFGSï¼Œç”¨äºå¤„ç†æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„æ•°æ®å¹¶è¡Œå’Œæ¨¡å‹å¹¶è¡Œã€‚

ç›¸æ¯”æ™®é€šçš„ SGD + æ™®é€šçš„ L-BFGS å®ç°è¦å¿«ä¸Šä¸å°‘ã€‚

å¼‚æ­¥ SGD ä¹‹å‰åœ¨æœºå™¨å­¦ä¹ é¢†åŸŸå¾ˆå°‘è¢«ç”¨åœ¨**éå‡¸çš„ä¼˜åŒ–é—®é¢˜ä¸Š**ï¼Œä½†æ˜¯ç»è¿‡è¯•éªŒéªŒè¯ä¹‹åå‘ç°å¼‚æ­¥ SGD ç”¨åœ¨ç¥ç»ç½‘ç»œä¸Šæ•ˆæœå¾ˆå¥½ï¼Œå°¤å…¶æ˜¯é…åˆ Adagrad è¿™ç§å­¦ä¹ ç‡ä¿®æ­£ç®—æ³•çš„æ—¶å€™ã€‚ç„¶ååœ¨èµ„æºè¶³å¤Ÿçš„æƒ…å†µä¸‹ï¼ŒL-BFGS çš„æ€§èƒ½ä¸ä¼šå¼±äº SGDã€‚

è®ºæ–‡ä¸­åšåˆ°çš„æœ€å¤§è§„æ¨¡æ˜¯æŠŠä¸€ä¸ªæ¨¡å‹æ‹†åˆ° 32 ä¸ªèŠ‚ç‚¹ä¸Šè¿›è¡Œæ¨¡å‹å¹¶è¡Œã€‚

## 2013 ICML - Deep Learning with COTS HPC

é¦–æ¬¡æŠŠåˆ†å¸ƒå¼æœºå™¨å­¦ä¹ é‡Œé¢çš„**æ•°æ®å¹¶è¡Œ**å’Œ**æ¨¡å‹å¹¶è¡Œ**å¼•å…¥æ·±åº¦å­¦ä¹ ã€‚

ä¸»è¦å®ç°åœ¨ InfiniBand ç½‘ç»œä¸Šï¼Œç„¶ååé‡åœ¨æ¨¡å‹å¹¶è¡Œä¸Šã€‚

To be read.

## 2014 ICASSP - On parallelizability of stochastic gradient descent for speech DNNS

è¿™ç¯‡æ–‡ç« æ˜¯ä»ç†è®ºä¸Šå¯¹æ¯”äº†æ¨¡å‹å¹¶è¡Œå’Œæ•°æ®å¹¶è¡Œä¸­åˆ†å¸ƒå¼ SGD è®­ç»ƒçš„æ•ˆç‡ï¼ŒæŒ‡å‡ºå¢å¤§ minibatch çš„å¤§å°å¯ä»¥æé«˜æ•°æ®å¹¶è¡Œè®­ç»ƒçš„æ•ˆç‡ã€‚

To be read.

## 2014 OSDI - Project Adam: Building an Efficient and Scalable Deep Learning Training System

å¾®è½¯åœ¨åˆ†å¸ƒå¼ DL è®­ç»ƒæ–¹é¢åšçš„å·¥ä½œã€‚

To be read.

## 2014 Proceedings of the VLDB Endowment - Marianaï¼š Tencent Deep Learning Platform and its Applications

è…¾è®¯åšçš„ä¸€ä¸ªå« Mariana çš„æ·±åº¦å­¦ä¹ å¹³å°ã€‚

To be read.

## 2015 ACM MM - SINGA: Putting Deep Learning in the Hands of Multimedia Users

ä¸€å¥—å« SINGA çš„åˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚

To be read.

## 2016 - Asynchrony begets momentum, with an application to deep learning

åˆ†æäº†å¼‚æ­¥ä¸**åŠ¨é‡æ³•è°ƒæ•´çš„å­¦ä¹ ç‡**ä¹‹é—´çš„å½±å“å…³ç³»ã€‚

> åŠ¨é‡æ³•æ˜¯ä¸€ç§æ¢¯åº¦ä¸‹é™é‡Œé¢å¯¹å­¦ä¹ ç‡è‡ªåŠ¨è°ƒèŠ‚çš„æ–¹æ³•ã€‚

To be read.

## 2016 - How to scale distributed deep learning

ç”¨ ImageNet å¯¹æ¯”äº†åŒæ­¥å’Œå¼‚æ­¥ SGD çš„å®æµ‹ç»“æœï¼ŒæŒ‡å‡ºå¯èƒ½åœ¨æ›´å¤§è§„æ¨¡ä¸‹å…¶å®åŒæ­¥ SGD æ•ˆæœæ›´å¥½ã€‚

To be read.

## 2016 SoCC - Ako: Decentralised deep learning with partial gradient exchange

å»ä¸­å¿ƒåŒ–ï¼ˆä¸å†é‡‡ç”¨ PS-Worker æ–¹å¼ï¼‰çš„åˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ æ€è·¯ã€‚

To be read.

## 2016 Eurosys - GeePS: Scalable Deep Learning on Distributed GPUs with a GPU-Specialized Parameter Server

è¿™ç¯‡æ–‡ç« å¾ˆå‰å®³äº†ï¼Œä¸»è¦å†…å®¹æ˜¯è¯´åšäº†ä¸€å¥—å« GeePS çš„ Parameter Server æœºåˆ¶ï¼Œä¸»è¦é’ˆå¯¹ GPU åšäº†ç‰¹åˆ«çš„ä¼˜åŒ–å’Œæ”¹è¿›ï¼Œå…‹æœäº†æ•°æ®å¹¶è¡Œå’Œæ¨¡å‹å¹¶è¡Œï¼ŒBSP å’Œå¼‚æ­¥è¿™äº›è€æ–¹æ³•ä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œæœ€ç»ˆç»“æœæ€§èƒ½çˆ†ç‚¸ã€‚GeePS è¿˜**æ”¯æŒåœ¨å¡ä¸Šè·‘è¶…è¿‡æ˜¾å­˜å®¹é‡çš„ç½‘ç»œ**ï¼Œç›´æ¥è§£å†³äº†å¯¹æ¨¡å‹å¹¶è¡Œçš„éœ€æ±‚ã€‚

èƒŒæ™¯ä»‹ç»éƒ¨åˆ†åˆ†æäº†ä¸€ä¸‹ Parameter Server æ¨¡å¼å­˜åœ¨çš„é—®é¢˜ï¼Œè¿™é‡Œä¹Ÿæœ‰æåˆ°å‰é¢ 13 å¹´é‚£ç¯‡ SSP æ¨¡å‹æ–¹é¢çš„å·¥ä½œï¼ˆâ€¦å…¶å®è¿™ç¯‡è®ºæ–‡è¿˜æ˜¯åŒä¸€æ‹¨äººåšçš„â€¦ï¼‰ã€‚è¦åº”ç”¨ PS æ¨¡å¼åˆ° GPU ä¸Šï¼Œé‡‡ç”¨å¤šä¸ª worker é…åˆå¤šä¸ª psï¼Œæ¯ä¸ªç‰©ç†èŠ‚ç‚¹å†…éƒ½æœ‰ ps å’Œ worker è¿™ç§å½¢å¼ä¼šæ¯”è¾ƒåˆé€‚ã€‚

[![img](http://jcf94.com/download/2017-08-18-paper-gpups1.png)](http://jcf94.com/download/2017-08-18-paper-gpups1.png)

ä½†æ˜¯ç›´æ¥ç®€å•åœ°æŠŠ ps æ¬åˆ° GPU ä¸Šæ•ˆæœéå¸¸ä¸å¥½ï¼Œåæ–‡æ¥ä¸‹æ¥å°±æ˜¯è®²ä»–ä»¬å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå³ä»–ä»¬æå‡ºæ¥çš„ GeePS æ˜¯æ€ä¹ˆåšçš„ã€‚

ç¬¬ä¸€ä¸ªä¼˜åŒ–ç­–ç•¥æ˜¯åœ¨ GPU ä¸Šåšä¸€ä¸ªå‚æ•° cacheï¼Œå—¯è¿™ä¸ªæ€æƒ³å¤§æ¦‚è·Ÿå¾€å¼‚æ­¥ PS é‡Œé¢å¼•å…¥æœ¬åœ° cacheï¼ˆåº”ç”¨ SSP æ¨¡å‹ï¼‰æ˜¯ä¸€ä¸ªé“ç†ã€‚å› ä¸ºå‰é¢çš„æ€§èƒ½ç“¶é¢ˆä¸»è¦åœ¨æ¯ä¸€æ¬¡æ¨é€å‚æ•°æ›´æ–°ä¸Šäº†ï¼Œå¼•å…¥äº† CPU è·Ÿ GPU ä¹‹é—´çš„æ•°æ®ä¼ è¾“ä¹‹åæ€»ä¼šæŠŠæ•´ä¸ªè®¡ç®—è¿‡ç¨‹å¡ä¸‹æ¥ã€‚

[![img](http://jcf94.com/download/2017-08-18-paper-gpups2.png)](http://jcf94.com/download/2017-08-18-paper-gpups2.png)

è¿™ç§æ–¹æ³•æå‡æ€§èƒ½çš„å…³é”®åœ¨äºèƒ½å¤ŸæˆåŠŸåœ°æŠŠè®¡ç®—å’Œ CPU/GPU çš„æ•°æ®æ‹·è´ç»™ overlap å¼€ï¼Œè¿™æ ·å°±èƒ½æœ€å¤§åŒ– GPU çš„ä½¿ç”¨ç‡å•¦ï¼ŒGPU åªè¦æ‹¿åˆ°äº†æ–°çš„ input æ•°æ®å°±èƒ½ä¸€ç›´è·‘ã€‚

ç¬¬äºŒä¸ªç­–ç•¥æ˜¯æ•°æ®çš„è¾“å…¥å’Œå‚æ•°çš„æ›´æ–°éƒ½æ˜¯ä»¥ batch ä¸ºå•ä½çš„ï¼Œåˆ©ç”¨äº† GPU çš„ SIMD ç‰¹æ€§ï¼Œå¢åŠ äº†æ•°æ®çš„ååé‡ï¼Œè¿™ä¸€å—è¯¦ç»†çš„è¦è§ä»–ä»¬å‰é¢çš„ä¸€ç¯‡æ–‡ç« ï¼ˆ[Exploiting Iterative-ness for Parallel ML Computations](http://jcf94.com/2017/12/20/2017-12-20-distributeddl/#2014-SoCC-Exploiting-Iterative-ness-for-Parallel-ML-Computations)ï¼‰ã€‚

ç¬¬ä¸‰ä¸ªå°±å‰å®³äº†ï¼Œç›®æµ‹åº”è¯¥å·¥ä½œé‡æŒºå¤§çš„ã€‚ä¸ºäº†è§£å†³æ¨¡å‹å¤ªå¤§ï¼ŒGPU ä¸Šæ”¾ä¸ä¸‹çš„é—®é¢˜ï¼Œä»–ä»¬æ‰‹åŠ¨ç»´æŠ¤äº†ä¸€ä¸ª GPU å’Œ CPU ä¹‹é—´çš„å†…å­˜æ± ï¼Œæ¯æ¬¡æŠŠä¸ç”¨çš„æ•°æ®æ¢åˆ°ä¸»å­˜ä¸Šï¼ŒæŠŠä¸‹ä¸€æ³¢è®¡ç®—éœ€è¦ç”¨çš„æ•°æ®æ¢åˆ° GPU ä¸Šã€‚

ç”¨æ‰‹åŠ¨ç»´æŠ¤çš„å†…å­˜æ± å®Œå…¨æ¥ç®¡æ•´ä¸ª GPU çš„å†…å­˜åˆ†é…ã€é‡Šæ”¾æ“ä½œï¼ŒCPU è·Ÿ GPU ä¹‹é—´çš„æ•°æ®ä¼ è¾“ç”¨å¦å¤–ä¸€ä¸ªçº¿ç¨‹åœ¨åå°å®Œæˆï¼ŒæŠŠè®¡ç®—æ—¶é—´å’Œæ•°æ®æ‹·è´å»¶è¿Ÿå®Œå…¨ overlap å¼€ã€‚ç”±äºç¥ç»ç½‘ç»œå±‚ä¸å±‚ä¹‹é—´çš„é¡ºåºæ€§æ˜¯æ˜¾ç¤ºå­˜åœ¨çš„ï¼Œå› æ­¤æ•°æ®åœ¨ GPU æ˜¾å­˜ä¸Šçš„æ¢å…¥æ¢å‡ºå°±æ˜¯å®Œå…¨å¯ä»¥åšåˆ°çš„äº†ã€‚

ç¬¬å››ç‚¹æ˜¯å¯¹ PS æ¨¡å¼ä¸‹å¼‚æ­¥æ–¹å¼çš„æ€è€ƒï¼Œè™½è¯´æŠŠ BSP æ”¹æˆå¼‚æ­¥çš„å¯ä»¥å¢åŠ è®¡ç®—èµ„æºçš„åˆ©ç”¨ç‡ï¼Œä½†æ˜¯æ”¶æ•›é€Ÿåº¦ä¼šæ”¾æ…¢æ˜¯è‚¯å®šçš„ï¼Œä¹‹å‰çš„ä¸å°‘ç ”ç©¶ä¹Ÿæ˜¯åœ¨è¿™ä¸¤ä¸ªæ–¹é¢ä½œäº†å–èˆï¼Œæ‰èƒ½è®©æœ€ç»ˆè®­ç»ƒåˆ°ç›¸åŒæ•ˆæœçš„æ€»ä½“æ—¶é—´æ›´çŸ­ã€‚è¿™ç¯‡æ–‡ç« åœ¨åŒæ­¥å»¶è¿Ÿèƒ½å¤Ÿä¿è¯çš„æƒ…å†µä¸‹ï¼Œæµ‹è¯•ç»“æœåå‘äºç”¨ BSP æ”¶æ•›æ•ˆæœä¼šæ›´å¥½ã€‚

> ä¸­é—´çš„è¯¦ç»†å®ç°å…ˆæ”¾ç€ï¼Œç•™å¾…ä¹‹åå›æ¥çœ‹ã€‚

## 2017 ATC - Poseidon: An Efficient Communication Architecture for Distributed Deep Learning on GPU Clusters

emmâ€¦è¿™ç¯‡æ–‡ç« è·Ÿä¸Šä¸€ç¯‡è¿˜æ˜¯åŒä¸€æ‹¨äººåšçš„ã€‚Motivationã€ç›®æ ‡ä»€ä¹ˆçš„åŸºæœ¬ä¸Šå·®ä¸å¤šï¼Œå·¥ä½œæ–¹å‘ä¸Šä»ä¸åŒçš„è§’åº¦å‡ºå‘æ¥åšã€‚

æ–‡ç« é¦–å…ˆæŒ‡å‡ºäº†é™åˆ¶åˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ å¯æ‰©å±•æ€§çš„ä¸¤ä¸ªç“¶é¢ˆï¼š

1. æ¯æ¬¡æ›´æ–°çš„æ¢¯åº¦éƒ½å¯èƒ½æ˜¯å¤§çŸ©é˜µï¼Œå¾ˆå®¹æ˜“å°±æŠŠç½‘ç»œå¸¦å®½ç»™å æ»¡ï¼›
2. ç”±äºç¥ç»ç½‘ç»œè¿ç®—çš„è¿­ä»£ç‰¹æ€§ï¼Œåœ¨å®Œæˆä¸€è½®è¿­ä»£ä¹‹åæ‰æ›´æ–°å‚æ•°ã€‚å› æ­¤å…¶é€šä¿¡è¡¨ç°æ˜¯çŸ­æ—¶é—´å†…æœ‰ä¸€ä¸ªé€šä¿¡é‡çš„æš´å¢ï¼Œè€Œå…¶ä»–æ—¶é—´æ²¡æœ‰é€šä¿¡ã€‚

æœ¬æ–‡è§£å†³é—®é¢˜çš„æ€è·¯ä¹Ÿä»è¿™ä¸¤ç‚¹å¼€å§‹å‡ºå‘ï¼š

1. æŠŠè¦æ›´æ–°çš„æ¢¯åº¦çŸ©é˜µåšä¸€å®šçš„åˆ’åˆ†ï¼Œé€šè¿‡é‡æ–°è°ƒåº¦ï¼Œåœ¨æ—¶é—´ä¸ŠæŠŠæ•´ä¸ªé€šä¿¡å¹³æ‘Šæ‰ï¼›
2. æƒ³åŠæ³•å‡å°‘æ¯æ¬¡æ›´æ–°çš„æ¢¯åº¦çŸ©é˜µçš„å¤§å°ï¼Œä»æ•´ä½“é€šä¿¡é‡ä¸Šåšæ–‡ç« ã€‚

æœ€åè¦è¾¾åˆ°çš„æ•ˆæœå‘¢ï¼Œä¹Ÿæ˜¯åˆ†ä¸¤æ–¹é¢ï¼šé¦–å…ˆæ•´ä¸ªç³»ç»Ÿçš„ååé‡å¢åŠ äº†ï¼ŒåŒæ—¶è¿­ä»£çš„æ”¶æ•›é€Ÿåº¦å¹¶ä¸å—å½±å“ï¼Œä¸éœ€è¦å¢åŠ è¿­ä»£æ¬¡æ•°å°±èƒ½è¾¾åˆ°ä¸€æ ·çš„æ•ˆæœã€‚

å‡å°‘æ¢¯åº¦çŸ©é˜µå¤§å°ç”¨çš„æ˜¯ä¸€ä¸ªå« SFBï¼ˆSufficient Factors Broadcastingï¼‰çš„æŠ€æœ¯ï¼Œå…·ä½“çš„æ–‡ç« [åœ¨è¿™é‡Œ](http://jcf94.com/2017/12/20/2017-12-20-distributeddl/#2015-Distributed-Machine-Learning-via-Sufficient-Factor-Broadcasting)ã€‚

ä½œè€…è®¤ä¸ºæ ¸å¿ƒçš„ç“¶é¢ˆè¿˜æ˜¯ä¸»è¦åœ¨**é€šä¿¡**ä¸Šã€‚

è¿™é‡Œç»™å‡ºäº†ä¸€ä¸ªå¯¹ Alexnet çš„ç²—ç•¥åˆ†æï¼ˆä¸æ˜¯ç‰¹åˆ«å‡†ç¡®ï¼Œä½†æ˜¯åŸºæœ¬ä¸Šæ˜¯åŒä¸€ä¸ªé‡çº§ï¼‰ï¼Œ**å‡å®šè®¡ç®—è·Ÿé€šä¿¡èƒ½å¤Ÿå®Œå…¨ overlap å¼€**ï¼Œç”¨ Taitan X èŠ‚ç‚¹æ¥åˆ†å¸ƒå¼è®­ç»ƒå¤§çº¦ä¹Ÿè¦è‡³å°‘ 26 Gbps çš„ç½‘ç»œå¸¦å®½ï¼Œè¿™ä¸ªå‹åŠ›å¯¹ä¸€èˆ¬çš„ä»¥å¤ªç½‘æ¥è¯´åŸºæœ¬ä¸Šæ˜¯å¾ˆéš¾åº”å¯¹çš„ã€‚å½“ç„¶ overlap è®¡ç®—å’Œé€šä¿¡è¿™äº‹æœ¬èº«å°±å¾ˆéš¾åšåˆ°äº†ã€‚

------

ä½œè€…é¦–å…ˆåˆ†æäº†æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„æ€è·¯ï¼š

å®šä¹‰è®­ç»ƒç¬¬ l å±‚ç½‘ç»œçš„å‰åå‘ä¸º ğ‘“ğ‘™ğ‘¡ftl å’Œ ğ‘ğ‘™ğ‘¡btlï¼Œé‚£ä¹ˆæ•´ä¸ªè®­ç»ƒçš„è®¡ç®—éƒ¨åˆ†æ˜¯è¿™æ ·çš„ï¼š



ğ¶ğ‘¡=[ğ‘“1ğ‘¡,ğ‘“2ğ‘¡,â€¦,ğ‘“ğ¿ğ‘¡,ğ‘ğ¿ğ‘¡,ğ‘ğ¿âˆ’1ğ‘¡,â€¦,ğ‘1ğ‘¡]Ct=[ft1,ft2,â€¦,ftL,btL,btLâˆ’1,â€¦,bt1]



åŠ ä¸Šé€šä¿¡åŒæ­¥éƒ¨åˆ†ï¼Œğ‘‚ğ‘™ğ‘¡Otl å’Œ ğ¼ğ‘™ğ‘¡Itl åˆ†åˆ«è¡¨ç¤ºç¬¬ l å±‚ç½‘ç»œå‚æ•°çš„è¾“å‡ºå’Œè¾“å…¥ï¼ˆæ›´æ–°ï¼‰ï¼š



ğ‘†ğ‘¡=[ğ‘‚ğ‘¡,ğ¼ğ‘¡]=[ğ‘‚ğ¿ğ‘¡,ğ‘‚ğ¿âˆ’1ğ‘¡,â€¦,ğ‘‚1ğ‘¡,ğ¼ğ¿ğ‘¡,ğ¼ğ¿âˆ’1ğ‘¡,â€¦,ğ¼1ğ‘¡]St=[Ot,It]=[OtL,OtLâˆ’1,â€¦,Ot1,ItL,ItLâˆ’1,â€¦,It1]



è¿™æ ·ç»„æˆçš„ä¸€æ¬¡ ğ¶ğ‘¡,ğ‘†ğ‘¡Ct,St å°±æ˜¯ä¸€æ¬¡è¿­ä»£çš„å®Œæ•´è¿‡ç¨‹äº†ã€‚

é‚£ä¹ˆå°±æå‡ºäº†è¿™é‡Œçš„ç¬¬ä¸€ä¸ªæ€è·¯ï¼š

- åˆ†å±‚æŠŠé€šä¿¡å’Œè®¡ç®—ç»™ overlap å¼€ï¼Œè¿™é‡Œç§°ä¸ºæ— ç­‰å¾…çš„åå‘ä¼ æ’­ç®—æ³•ï¼ˆWFBPï¼‰

é€šä¿¡çš„æ•°æ®ä¾èµ–å…³ç³»åªåœ¨åŒä¸€å±‚å†…ï¼Œå³ï¼š ğ‘ğ‘™ğ‘¡btl ç»“æŸä¹‹åå°±å¯ä»¥é©¬ä¸Šåš ğ‘‚ğ‘™ğ‘¡Otl å’Œ ğ¼ğ‘™ğ‘¡Itl äº†ï¼Œå³ç¬¬ l å±‚çš„å‚æ•°åŒæ­¥å¯ä»¥è·Ÿç¬¬ l-1 ä»¥åŠä»¥åå±‚çš„åå‘è®¡ç®—åŒæ—¶è¿›è¡Œã€‚ç¤ºæ„å›¾å¦‚ä¸‹ï¼š

[![img](http://jcf94.com/download/2017-08-18-paper-overlap.png)](http://jcf94.com/download/2017-08-18-paper-overlap.png)

è¿™ç§æ€è·¯å°¤å…¶é€‚ç”¨äºå‚æ•°é›†ä¸­åœ¨åå‡ å±‚ï¼ˆä¾‹å¦‚åå‡ å±‚æ˜¯å…¨è¿æ¥ï¼‰ï¼Œç„¶åè®¡ç®—é›†ä¸­åœ¨å‰å‡ å±‚ï¼ˆä¾‹å¦‚å‰å‡ å±‚æ˜¯å·ç§¯ï¼‰è¿™æ ·çš„ç½‘ç»œï¼ˆä¾‹å¦‚ VGG å’Œ AdamNetï¼‰ï¼Œè¿™æ ·å°±èƒ½**æŠŠé¡¶å±‚çš„é€šä¿¡æ—¶é—´æ©è—åœ¨åº•å±‚çš„è®¡ç®—æ—¶é—´**ä¸­ã€‚

å¤§æ¦‚æ˜¯è¿™ç§æ ·å­ï¼š



[ğ¶ğ‘¡,ğ‘†ğ‘¡]=[ğ‘“1ğ‘¡,ğ‘“2ğ‘¡,â€¦,ğ‘“ğ¿ğ‘¡,ğ‘ğ¿ğ‘¡,ğ‘ğ¿âˆ’1ğ‘¡,ğ‘ğ¿âˆ’2ğ‘¡â€¦,ğ‘1ğ‘¡] [ğ‘‚ğ¿ğ‘¡,ğ‘‚ğ¿âˆ’1ğ‘¡,â€¦,ğ‘‚1ğ‘¡] [ğ¼ğ¿ğ‘¡,ğ¼ğ¿âˆ’1ğ‘¡,â€¦,ğ¼1ğ‘¡](1)(1)[Ct,St]=[ft1,ft2,â€¦,ftL,btL,btLâˆ’1,btLâˆ’2â€¦,bt1] [OtL,OtLâˆ’1,â€¦,Ot1] [ItL,ItLâˆ’1,â€¦,It1]



ä½†æ˜¯è¿™æ ·å¯¹äºå¸¦å®½å—é™çš„ç½‘ç»œæ¥è¯´ä»ç„¶ä¸å¤Ÿï¼Œæ‰€ä»¥æœ‰äº†æ¥ä¸‹æ¥çš„ç¬¬äºŒä¸ªæ€è·¯ï¼š

- é‡‡ç”¨ PS å’Œ SFB æ··åˆçš„é€šä¿¡æœºåˆ¶

æ­£å¦‚ä¸Šé¢æ‰€åˆ†æçš„ï¼Œäº‹å®ä¸Šä¸åªæ˜¯ç¥ç»ç½‘ç»œä¸åŒå±‚çš„è®¡ç®—å’Œé€šä¿¡å¯ä»¥æ— å…³ï¼Œä¸åŒå±‚ä¹‹é—´çš„é€šä¿¡ä¹Ÿæ˜¯å®Œå…¨å¯ä»¥ç‹¬ç«‹çš„ï¼Œå› æ­¤è€ƒè™‘å¯¹ä¸åŒå±‚æ•°æ®çš„ç‰¹ç‚¹é‡‡ç”¨ä¸åŒçš„æ–¹å¼è¿›è¡Œç»„ç»‡é€šä¿¡ã€‚PS æ¨¡å¼æˆ–è€… SFB æ¨¡å¼ï¼š

[![img](http://jcf94.com/download/2017-08-18-paper-pssfb.png)](http://jcf94.com/download/2017-08-18-paper-pssfb.png)

å¹¶ä¸”ç¥ç»ç½‘ç»œçš„ç»“æ„æ˜¯åªè¦è®­ç»ƒå¼€å§‹äº†ï¼Œè‡ªå§‹è‡³ç»ˆéƒ½ä¸ä¼šå†æ”¹å˜ï¼Œå› æ­¤å¯ä»¥äº‹å…ˆç®—å‡ºå‚æ•°çš„æ€»é‡æ¥ä¼°è®¡æ•´ä¸ªç½‘ç»œä¼šäº§ç”Ÿçš„é€šä¿¡å¼€é”€ï¼Œåœ¨è®­ç»ƒå¼€å§‹å‰å°±èƒ½å¤Ÿé€‰æ‹©åˆé€‚çš„é€šä¿¡ç»„ç»‡æ–¹å¼ã€‚

è¿™é‡Œåˆä¸¾äº†ä¸ªä¾‹å­ï¼š

VGG19ï¼Œå‡å®š batch size K = 32ï¼Œ8 ä¸ª PS å’Œ 8 ä¸ª Workerï¼Œå‚æ•°å‡åˆ†åœ¨ 8 å° PS ä¸Šï¼Œå…¨è¿æ¥å±‚ M å’Œ N éƒ½æ˜¯ 4096ã€‚2 ä¸ªå…¨è¿æ¥å±‚æ¯ä¸€æ­¥è¿­ä»£äº§ç”Ÿ 2 * 4096 * 4096 = 34M ä¸ªå‚æ•°ã€‚

PS æ¨¡å¼ä¸‹ï¼šæ¯ä¸ª Worker æ¯æ¬¡è¦å‘é€ **34M** ä¸ªå‚æ•°ï¼Œæ¯ä¸ª PS ç®¡ 34M/8 ä¸ªå‚æ•°ï¼Œä½†æ˜¯è¦ä» 8 ä¸ª Worker é‚£é‡Œæ¥æ”¶ï¼Œæ‰€ä»¥æ€»çš„é€šä¿¡æ•°æ®é‡è¿˜æ˜¯ **34M**ã€‚å¦‚æœå®é™…ç‰©ç†æœºå°± 8 å°ï¼Œæ¯å°ä¸Šé¢è·‘ä¸€ä¸ª PS å’Œä¸€ä¸ª Workerï¼Œé‚£ä¹ˆæ¯å°æœºä¸Šæœ¬åœ°æ›´æ–° 34M/8 çš„æ•°æ®ï¼Œæ¯æ¬¡è¦é€å‡ºå» 7/8 * 34M çš„æ•°æ®ï¼Œå†æ”¶å›æ¥ 7 ä¸ª 34M/8 çš„æ•°æ®ï¼Œä¸€å…± 2 * 7/8 * 34M = **58.7M** çš„æ•°æ®é‡ã€‚

SFB æ¨¡å¼ä¸‹ï¼šï¼ˆè¿™ç§é€šä¿¡æ¨¡å¼æˆ‘è¿˜æ²¡ç»†çœ‹ï¼Œæ‰€ä»¥ä¸çŸ¥é“ä¸ºä»€ä¹ˆè¿™ä¹ˆç®—ï¼‰æ²¡æœ‰ PSï¼Œç›´æ¥æ˜¯ 8 ä¸ª Worker è¿›è¡Œæ•°æ®å¤„ç†ï¼Œæ¯ä¸ªèŠ‚ç‚¹éœ€è¦è´Ÿè´£çš„é€šä¿¡é‡åªæœ‰ 2 * K *(M + N)(P1 -1) = 2 * 32 * 8192 * 7 = **3.7M** çš„æ•°æ®é‡ã€‚è™½ç„¶æ”¶åˆ°æ•°æ®ä¹‹åè¦æ¢å¤æˆæ¢¯åº¦çŸ©é˜µéœ€è¦é¢å¤–çš„è¿ç®—ï¼Œä½†æ˜¯è¿™è·ŸèŠ‚çœä¸‹æ¥çš„é€šä¿¡æ—¶é—´ç›¸æ¯”æ˜¯å¯ä»¥å¿½ç•¥ä¸è®¡çš„ã€‚

å·ç§¯å±‚çš„æ›´æ–°æ¢¯åº¦ç”±äºæ˜¯ä¸å¯åˆ†è§£çš„ï¼Œå¹¶ä¸”æ˜¯ç¨€ç–çš„ï¼Œæ‰€ä»¥è¿˜æ˜¯é‡‡ç”¨ PS æ¨¡å¼æ›´å¥½ã€‚

æ‰€ä»¥æ ¹æ®ä¸åŒå±‚çš„å‚æ•°ç‰¹æ€§é‡‡ç”¨ä¸åŒçš„é€šä¿¡æœºåˆ¶çš„æ–¹æ³•æ˜¯æœ‰å¾ˆå¤§æ½œåŠ›çš„ã€‚

------

æ•´ä¸ª Poseidon ç³»ç»Ÿçš„è®¾è®¡åˆ†æˆä¸‰ä¸ªéƒ¨åˆ†ï¼š

- Coordinatorï¼šç”¨äºç»´æŠ¤ç½‘ç»œæ¨¡å‹å’Œé›†ç¾¤è®¾å¤‡ä¹‹é—´çš„é…ç½®å…³ç³»

é›†ç¾¤ä¸­ worker å’Œ ps çš„æ•°é‡ï¼Œå¯¹åº”çš„ ip åœ°å€ï¼Œç½‘ç»œæ¨¡å‹çš„ç»“æ„ç­‰ç­‰ã€‚è´Ÿè´£å»ºç«‹å„èŠ‚ç‚¹ä¹‹é—´çš„é€šä¿¡ç«¯å£ï¼Œåˆ†æç½‘ç»œæ¨¡å‹ï¼Œå†³å®šå“ªäº›å‚æ•°ç”¨ PS å“ªäº›å‚æ•°ç”¨ SFBã€‚

å½“ç„¶è¿™äº›æ•°æ®æ˜¯åœ¨åˆå§‹åŒ–çš„æ—¶å€™å°±å®Œæˆäº†ã€‚

- KV storeï¼šä¸€ä¸ªå…±äº«å†…å­˜çš„é”®å€¼å¯¹å­˜å‚¨éƒ¨ä»¶ï¼Œå…¶å®å°±æ˜¯ Parameter Server

ä¸ºä»€ä¹ˆè¿™é‡Œçš„ PS è¦çªå‡ºâ€é”®å€¼å¯¹â€œè¿™ä¸ªæ¦‚å¿µå‘¢ï¼Ÿ

Poseidon åœ¨è¿™é‡Œåšäº†ä¸€ä¸ªæ“ä½œï¼Œ**å‚æ•°ä¸æ˜¯æŒ‰ç…§å±‚æ¥åˆ’åˆ†çš„ï¼ˆï¼ï¼ï¼ï¼‰**ï¼Œè€Œæ˜¯æŠŠæ‰€æœ‰çš„å‚æ•°æŒ‰ç…§ 2MB åˆ’åˆ†ä¹‹åå†å‡åˆ†åˆ°å„ä¸ª PS ä¸Šå»ï¼Œè¿™æ ·å°±èƒ½ä¿è¯æ¯ä¸ª PS ä¸Šé¢å­˜å‚¨çš„**æ•°æ®é‡å°½å¯èƒ½åœ°ä¸€è‡´**ï¼Œè®©å„ä¸ªèŠ‚ç‚¹éœ€è¦çš„ç½‘ç»œå¸¦å®½å°½å¯èƒ½åœ°å¹³å‡ã€‚

å¦å¤–è¿˜æœ‰ checkpoint çš„è®¾è®¡ï¼Œä¿å­˜å¤šä¸ªé˜¶æ®µçš„å‚æ•°ç”¨äºå®¹é”™æ¢å¤ç­‰ç­‰ã€‚

- Client Libraryï¼šç”¨äºé€‚é…åˆ°ä¸åŒçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­

å¯¹æ¯ä¸ªå±‚éƒ½å•ç‹¬åˆ›å»ºä¸€ä¸ª syncer è´Ÿè´£å¤„ç†å…¶å‚æ•°ä¸€è‡´æ€§ã€‚

åœ¨ CPU ä¸Šç»´æŠ¤ä¸€ä¸ªçº¿ç¨‹æ± ï¼ˆç”¨äºåå°å¤„ç†ç½‘ç»œé€šä¿¡ï¼‰ï¼Œåœ¨ GPU ä¸Šç»´æŠ¤ä¸€ä¸ª stream æ± ï¼ˆç”¨äºåå°å¤„ç† CPU å’Œ GPU ä¹‹é—´çš„æ•°æ®æ‹·è´ï¼‰ã€‚

------

ä¹‹å‰ä½œè€…çš„æ–‡ç« é‡Œé¢ä¹Ÿæåˆ°äº† BSP çš„æ”¶æ•›æ€§ç›¸å¯¹å¼‚æ­¥æ¥è¯´å§‹ç»ˆè¿˜æ˜¯æ›´ç¨³å®šçš„ï¼Œæœ‰äº†ä¸Šé¢é‚£ä¸ª**åˆ†å±‚åŒæ­¥ã€é€šä¿¡å‡ ä¹å®Œå…¨æ©è—åœ¨è®¡ç®—èƒŒå**çš„è®¾è®¡ä¹‹åï¼ŒBSP è·Ÿå¼‚æ­¥ä¹‹é—´çš„å»¶è¿Ÿå·®è·å¯èƒ½å·²ç»èƒ½å¤Ÿå‡å°‘åˆ°è¶³ä»¥å¿½ç•¥çš„ç¨‹åº¦äº†ã€‚

å› æ­¤åœ¨å‚æ•°ä¸€è‡´æ€§æ–¹é¢çš„ç»´æŠ¤ä¸Šï¼ŒPoseidon ç›´æ¥é‡‡ç”¨äº† BSP åŒæ­¥ã€‚

worker è¿™è¾¹ï¼Œæ¯ä¸ª client library ç»´æŠ¤ä¸€ä¸ªé•¿ä¸º syncer æ•°çš„ 01 å‘é‡ï¼Œæ¯æ¬¡è¿­ä»£å¼€å§‹å‰åˆå§‹åŒ–ä¸º 0ï¼Œå½“ä¸€å±‚çš„æ•°æ®åŒæ­¥å®Œäº†ä¹‹åè®¾ä¸º 1ï¼Œå½“æ•´ä¸ªå‘é‡å…¨ 1 æ—¶å°±å¯ä»¥è¿›å…¥ä¸‹ä¸€ä¸ªè¿­ä»£äº†ã€‚

PS è¿™è¾¹ï¼ŒKV stroe åœ¨æ¯æ¬¡è¿­ä»£å¼€å§‹å‰ç»´æŠ¤ä¸€ä¸ªå€¼ä¸º 0 çš„è®¡æ•°å™¨ï¼Œæ¯å½“æœ‰ä¸€ä¸ª KV æ›´æ–°è®¡æ•°åŠ ä¸€ï¼Œå½“è®¡æ•°å™¨è¾¾åˆ° worker çš„æ•°é‡æ—¶ï¼Œå‘èµ·ä¸€æ¬¡å‚æ•°å¹¿æ’­ã€‚

æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„ä¼ªä»£ç ï¼š

```

```

Copy

------

åé¢æ˜¯ evaluationï¼Œæµ‹è¯•ç»“æœå°±æ˜¯å¾ˆå¼ºâ€¦å„æ–¹é¢éƒ½å¾ˆå¼ºã€‚

## 2015 - Poseidon: A system architecture for efficient GPU-based deep learning on multiple machines

è¿™ç¯‡ paper æ˜¯åœ¨ä¸Šé¢é‚£ç¯‡å‘å‡ºæ¥ä¹‹å‰æ”¾åœ¨ arxiv.org ä¸Šçš„ï¼Œåº”è¯¥ç®—æ˜¯æ­£ç¯‡å‰çš„ä¸€äº›åŸºç¡€å·¥ä½œï¼Œçœ‹å®Œ 2017 å¹´çš„æ­£ç¯‡å†çœ‹ä¸‹è¿™ä¸ªã€‚

## 2017 - Can Decentralized Algorithms Outperform Centralized Algorithms A Case Study for Decentralized Parallel Stochastic Gradient Descent

åˆä¸€ç¯‡å»ä¸­å¿ƒåŒ–æ€è·¯çš„æ–‡ç« ã€‚

To be read.

## 2017 ICML - Device Placement Optimization with Reinforcement Learning

Google åšçš„å…³äºæ¨¡å‹å¹¶è¡Œä¸­ Op å’Œ Device å¯¹åº”å…³ç³»çš„ç ”ç©¶ã€‚

åœ¨å¤šå—å¡ä¸Šåšæ¨¡å‹å¹¶è¡Œæ—¶éœ€è¦è€ƒè™‘æŠŠæ•´ä¸ªç½‘ç»œçš„å“ªäº›éƒ¨åˆ†åˆ†åœ¨å“ªç§è®¾å¤‡ä¸Šï¼Œè¿™ç¯‡æ–‡ç« çš„æ€è·¯æ˜¯å…ˆç”Ÿæˆä¸€å¥— Op å’Œ Device çš„å¯¹åº”å…³ç³»ï¼Œç„¶åæ‰”è¿› TensorFlow é‡Œé¢è·‘ï¼Œè·‘å®Œç»“æœå†åé¦ˆåˆ°ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ çš„ç½‘ç»œé‡Œé¢å»ï¼Œè®©ç½‘ç»œå»è‡ªåŠ¨é‡æ–°è°ƒæ•´ Op å’Œ Device çš„å¯¹åº”å…³ç³»ï¼Œç›´åˆ°å¾—åˆ°ä¸€å¥—æœ€é«˜æ•ˆçš„åˆ†é…æ–¹æ¡ˆã€‚

> 666666ï¼

## 2017 - ChainerMN: Scalable Distributed DeepLearning Framework

ä¸‹é¢åˆ—çš„é‚£ä¸ª 15 åˆ†é’Ÿè·‘å®Œ ImageNet çš„æ—¥æœ¬æœºæ„ç”¨çš„æ˜¯ä»–ä»¬è‡ªå·±å†™çš„æ¡†æ¶ï¼Œåå­—å°±å« ChainerMNã€‚

To be read.

## 2018 NIPS - Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training

åˆšåˆšçœ‹åˆ°çš„ä¸€ç¯‡ NIPS çš„å·¥ä½œï¼Œå—¯ï¼Œä»é¢˜ç›®å°±åŸºæœ¬ä¸Šå¯ä»¥çŸ¥é“å†™çš„æ˜¯å•¥äº†ã€‚

Introduction ä¸­é¦–å…ˆè®¨è®ºäº†ä¸€ä¸‹ç½‘ç»œå±‚ã€æ•°æ®é‡çš„å¢é•¿å¸¦æ¥çš„è®¡ç®—é‡çš„éœ€æ±‚ï¼Œå°½ç®¡å„ç§ç¥ç»ç½‘ç»œåŠ é€Ÿå™¨ï¼ˆGPUã€ASIC ç­‰ç­‰ï¼‰å’Œå¹¶è¡Œè®¡ç®—çš„å‘å±•ç¼“è§£äº†å¾ˆå¤§çš„å‹åŠ›ï¼Œä»å¦ä¸€æ–¹é¢å´æ›´**åŠ å‰§äº†å¤šæœºé€šä¿¡çš„ Overhead é€ æˆçš„å½±å“**ï¼Œæ¯•ç«Ÿå‰åå‘çš„è®¡ç®—æ—¶é—´æ˜¯å‡å°‘äº†ï¼Œä½†æ˜¯é€šä¿¡æ—¶é—´ä¸å˜å•Šï¼Œåœ¨æ•´ä½“ä¸€æ¬¡è®­ç»ƒè¿­ä»£ä¸­å çš„æ¯”é‡å°±å¢å¤§äº†ã€‚

è¿™ç¯‡æ–‡ç« é¦–å…ˆ**åˆ†æ**äº†ç¥ç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­çš„é€šä¿¡æ—¶é—´å’Œè®¡ç®—æ—¶é—´çš„å…³ç³»ï¼Œç„¶å**æå‡ºäº†ä¸€å¥—æ¨¡å‹**æ¥è¯„ä¼°å„æ–¹é¢å› ç´ å¯¹å®ƒä»¬çš„å½±å“ï¼ˆä¾‹å¦‚å»¶è¿Ÿã€é›†ç¾¤è§„æ¨¡ã€ç½‘ç»œå¸¦å®½ã€ç¥ç»ç½‘ç»œæ¨¡å‹ç­‰ç­‰ï¼‰ï¼Œåœ¨è¿™å¥—è¯„ä¼°æ¨¡å‹çš„åŸºç¡€ä¸Šæ¥ä¸‹æ¥**æ¨å‡ºäº† Pipe-SGD æ¡†æ¶**æ¥å®ç°ä»–ä»¬æƒ³è¦çš„è®­ç»ƒæœºåˆ¶ï¼Œæœ€ç»ˆåœ¨**è¯„ä¼°æµ‹è¯•**ä¸­å¾—åˆ°äº†å¾ˆå¥½çš„ç»“æœã€‚

Background éƒ¨åˆ†æ˜¯å¯¹ç¥ç»ç½‘ç»œä»¥åŠåˆ†å¸ƒå¼è®­ç»ƒçš„ä»‹ç»ï¼Œå€¼å¾—ä¸€æçš„æ˜¯æœ€åæåˆ°å¥½å¤šäººä¸ºäº†å‡å°‘é€šä¿¡æ—¶é—´ä¼šé‡‡ç”¨å‹ç¼©çš„æ–¹æ¡ˆï¼Œä¾‹å¦‚ä½æ¯”ç‰¹é‡åŒ–ã€ä¼ è¾“æ—¶ç›´æ¥æ‰”æ‰æŸäº›å±‚çš„æ¢¯åº¦ç­‰ç­‰ã€‚

> æ—¢ç„¶ Background é‡Œé¢æåˆ°äº†å‹ç¼©ï¼Œè¯´æ˜åé¢ä»–ä»¬çš„æ¡†æ¶ä¸­ä¹Ÿæœ‰å‹ç¼©æ–¹é¢çš„å·¥ä½œã€‚

------

ä¸‹å›¾åˆ†åˆ«æ˜¯ä¸­å¿ƒåŒ–çš„ PS-Worker å¼‚æ­¥æ¨¡å¼ã€å»ä¸­å¿ƒåŒ–çš„åŒæ­¥æ¨¡å¼ä»¥åŠæœ¬æ–‡çš„æµæ°´çº¿æ¨¡å¼çš„ç¤ºæ„å›¾ã€‚

[![img](http://jcf94.com/download/2017-12-20-distributeddl-pipsgd.png)](http://jcf94.com/download/2017-12-20-distributeddl-pipsgd.png)

> é©¬åç‚®ä¸€ä¸‹ï¼Œçœ‹åˆ° c å›¾çš„æ—¶å€™æˆ‘æƒŠäº†ä¸€ä¸‹â€¦â€¦å¤§æ¦‚å»å¹´å¹´åº•çš„æ—¶å€™ä¹Ÿæƒ³åˆ°äº†ç±»ä¼¼è¿™ç§æ€è·¯ï¼Œæ— å¥ˆé™äºä¸€ç›´åšçš„æ¡†æ¶éƒ½æ˜¯ TensorFlowï¼Œæ²¡æƒ³åˆ°åº”è¯¥æ€ä¹ˆåœ¨ TF é‡Œé¢å®ç°ï¼Œäºæ˜¯ä¸€ç›´æ²¡æœ‰æŠŠæƒ³æ³•å˜æˆå®ç°ã€‚
>
> å¦å¤–ä¸€ç‚¹æ˜¯ï¼Œç”±äº TensorFlow æœ¬èº«çš„æ•°æ®æµè®¾è®¡ï¼Œä¸€è½®è¿­ä»£ä¸­çš„è®¡ç®—å’Œé€šä¿¡æœ¬å°±èƒ½å¤Ÿå¾ˆå¤§ç¨‹åº¦ä¸Šè‡ªåŠ¨ overlap èµ·æ¥ï¼Œå› æ­¤å³ä½¿åœ¨ TF ä¸­å®ç°äº†ä¹Ÿå¯èƒ½æ„ä¹‰ä¸å¤§ã€‚

è¿™é‡ŒæŠŠæ¯ä¸€æ¬¡çš„è®­ç»ƒè¿­ä»£åˆ†æˆä¸‰ä¸ªéƒ¨åˆ†ï¼šæ¨¡å‹æ›´æ–°ã€æ¢¯åº¦è®¡ç®—ã€æ¢¯åº¦ä¼ è¾“ã€‚

åœ¨ä¸€ä¸ªå¸¸è§„çš„åŒæ­¥è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸€è½®è¿­ä»£ä¸­çš„ä¸‰ä¸ªéƒ¨åˆ†æ˜¯ç›¸äº’ä¾èµ–çš„ï¼Œå¦‚æœç”¨ T è¡¨ç¤ºæ€»çš„è®­ç»ƒè¿­ä»£æ¬¡æ•°ï¼Œåˆ™æ•´ä¸ªè®­ç»ƒæ—¶é—´å¯ä»¥è¡¨ç¤ºæˆè¿™æ ·ï¼š



ğ‘™ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™_ğ‘ ğ‘¦ğ‘›ğ‘=ğ‘‡âˆ—(ğ‘™ğ‘¢ğ‘+ğ‘™ğ‘ğ‘œğ‘šğ‘+ğ‘™ğ‘ğ‘œğ‘šğ‘š)ltotal_sync=Tâˆ—(lup+lcomp+lcomm)



Pipe-SGD çš„æ€æƒ³å‘¢åˆ™æ˜¯æŠŠè¿™ç§é€šä¿¡å’Œè®¡ç®—çš„ä¾èµ–å…³ç³»è§£å¼€ï¼Œå¦‚æœä¸€ä¸ª Worker ä¸Šæ˜¯å¤šæ¡æµæ°´çº¿äº¤æ›¿è¿›è¡Œï¼Œåˆ™é€šä¿¡å’Œè®¡ç®—çš„æ—¶é—´å°±æœ‰æœºä¼šå®Œå…¨ overlap å¼€äº†ï¼Œæœ¬è½®è¿­ä»£çš„æ•°æ®åªä¸å‰ K è½®çš„è¿­ä»£æ•°æ®ç›¸å…³ï¼Œè€Œç›¸é‚»çš„ä¸¤æ¬¡è¿­ä»£ä¹‹é—´åˆ™å®Œå…¨æ²¡æœ‰ä¾èµ–äº†ã€‚åœ¨è¿™ç§æ–¹å¼ä¸‹ï¼Œæ€»çš„æ—¶é—´å¯ä»¥è¡¨ç¤ºä¸ºï¼š



ğ‘™ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™_ğ‘ğ‘–ğ‘ğ‘’=ğ‘‡/ğ¾âˆ—(ğ‘™ğ‘¢ğ‘+ğ‘™ğ‘ğ‘œğ‘šğ‘+ğ‘™ğ‘ğ‘œğ‘šğ‘š)ltotal_pipe=T/Kâˆ—(lup+lcomp+lcomm)



æ›´è¿›ä¸€æ­¥çš„åˆ†ææ˜¯ï¼Œç”±äºç½‘ç»œä¸­çš„è®¡ç®—å’Œé€šä¿¡æ—¶é—´å¾€å¾€å¾ˆéš¾å®Œå…¨å¯¹ç­‰èµ·æ¥ï¼Œäº‹å®ä¸Šæ•´ä¸ªè®¡ç®—è¿‡ç¨‹æ˜¯**èµ„æºå—é™ï¼ˆResource Boundï¼‰**çš„ï¼Œåˆ™æœ€åå®é™…å—é™çš„ç»“æœæ˜¯è¦çœ‹è®¡ç®—å’Œé€šä¿¡å“ªéƒ¨åˆ†æ›´èŠ±æ—¶é—´ï¼š



ğ‘™ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™_ğ‘ğ‘–ğ‘ğ‘’=ğ‘‡âˆ—ğ‘šğ‘ğ‘¥(ğ‘™ğ‘¢ğ‘+ğ‘™ğ‘ğ‘œğ‘šğ‘,ğ‘™ğ‘ğ‘œğ‘šğ‘š)ltotal_pipe=Tâˆ—max(lup+lcomp,lcomm)



ä¸‹é¢æ›´è¿›ä¸€æ­¥åœ°ç»™å‡ºäº†ä¸€ä¸ªæ›´è¯¦ç»†çš„æ—¶é—´æ¨¡å‹ï¼ŒæŠŠç½‘ç»œå»¶è¿Ÿã€æ¨¡å‹çš„å‚æ•°é‡ã€ä¼ è¾“å¸¦å®½ã€worker æ•°é‡ç­‰ç­‰éƒ½åŒ…å«åœ¨å†…äº†ï¼Œæœ€ç»ˆåˆ†æå®Œäº†ç»™å‡ºäº†è¿™æ ·ä¸€ä¸ªç»“è®ºï¼š

Pipe-SGD é€‰æ‹© K=2 ä¸ºæœ€ä½³ï¼Œæ•´ä¸ªè®¡ç®—è¿‡ç¨‹æ˜¯è®¡ç®—å—é™çš„ï¼Œå¹¶ä¸”åº”è¯¥é‡‡ç”¨é¡ºåºçš„æ¢¯åº¦ä¼ è¾“åŸåˆ™ã€‚

> è¿™é‡Œçš„é¡ºåºæ¢¯åº¦æ›´æ–°åŸåˆ™æŒ‡çš„æ˜¯æŠŠ**æ¢¯åº¦è®¡ç®—**å’Œ**æ¢¯åº¦ä¼ è¾“**è¿™ä¸¤ä¸ªè¿‡ç¨‹å®Œå…¨åˆ†å¼€ï¼Œå³è®¡ç®—å®Œæ•´ä¸ªç½‘ç»œçš„æ‰€æœ‰æ¢¯åº¦ä¹‹åå†ä¸€æ¬¡æ€§ä¼ è¾“å®Œï¼Œåœ¨ TensorFlow ä¸­é»˜è®¤å¹¶ä¸å­˜åœ¨è¿™ç§åˆ†ç¦»å…³ç³»ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯è‡ªåŠ¨çš„åˆ†å±‚æ¢¯åº¦ä¼ è¾“ï¼Œä¸€å±‚æ¢¯åº¦ç®—å®Œä¹‹åé©¬ä¸Šå°±å¯ä»¥å¼€å§‹ä¼ è¾“è¿‡ç¨‹ï¼Œå¹¶ä¸”è¿™ä¸ªä¼ è¾“å¹¶ä¸å½±å“åç»­å…¶ä»–å±‚çš„æ¢¯åº¦è®¡ç®—ã€‚
>
> â€¦â€¦ è¯è¯´æˆ‘è§‰å¾—è¿™é‡Œçš„ç»“è®ºç›´æ¥æƒ³ä¹Ÿå¾ˆå®¹æ˜“å¾—å‡ºæ¥å•Šï¼Œå¯èƒ½ä¸¥è°¨çš„æ•°å­¦æ¨¡å‹æ¨è®ºå°±æ˜¯äººå®¶ä¸ºä»€ä¹ˆèƒ½ä¸­ NIPS çš„åŸå› å§ã€‚

å¦å¤–è¿˜æœ‰ä¸ºä»€ä¹ˆè¿™é‡Œè¦ç‰¹æ„æåˆ°å‹ç¼©å‘¢ï¼Ÿ

ä¸‹å›¾çš„ a æ˜¯æ— å‹ç¼©æƒ…å†µä¸‹çš„é€šä¿¡å’Œ Reduce è®¡ç®—å…³ç³»ï¼Œå¯ä»¥çœ‹åˆ°å³ä½¿é‡‡ç”¨äº†æµæ°´çº¿çš„æ–¹å¼ï¼ŒReduce çš„å®ç°åºåˆ—ä¸Šè¿˜æ˜¯ä¼šæœ‰å¤§é‡çš„ç©ºé—²ã€‚

[![img](http://jcf94.com/download/2017-12-20-distributeddl-allreduce.png)](http://jcf94.com/download/2017-12-20-distributeddl-allreduce.png)

è€Œå¦‚ b å›¾æ‰€ç¤ºï¼Œæ¢¯åº¦å‹ç¼©æ“ä½œå‡å°‘äº†ä¼ è¾“æ—¶é—´ï¼Œä½†å´ä¼šç•¥å¾®å¢åŠ ä¸€äº›è®¡ç®—é‡ï¼Œè€Œè¿™ç§å¢åŠ çš„è®¡ç®—é‡åˆ°äº†æµæ°´çº¿ä¸­åè€Œå¯ä»¥å¾ˆå¥½åœ°è¢«éšè—æ‰ã€‚

> ã€‚ã€‚ã€‚

æœ€åçš„å®éªŒéªŒè¯éƒ¨åˆ†è¯´å®è¯æˆ‘æ˜¯æ¯”è¾ƒå¤±æœ›çš„ï¼Œ4 å°å• GPU èŠ‚ç‚¹ç»„æˆçš„é›†ç¾¤å®åœ¨ä¸æ˜¯ä¸ªå¤ªå¤§çš„è§„æ¨¡å•Šâ€¦â€¦è€Œä¸”è¿™é‡Œä¹Ÿæ²¡æœ‰ç»™å‡ºä¸å…¶ä»–æ¡†æ¶çš„å¯¹æ¯”æ€§èƒ½æ¥ã€‚

## 2018 - Beyond data and model parallelism for deep neural networks

çœ‹çš„æ—¶å€™è¿™ç¯‡æ–‡ç« è¿˜åœ¨ SysML19 å®¡ç¨¿ä¸­ã€‚

ä¸»è¦å·¥ä½œæ˜¯å»ºç«‹äº†ä¸€å¥—åä¸º SOAPï¼ˆSampleï¼ŒOperationï¼ŒAttributeï¼ŒParameterï¼‰çš„å¹¶è¡Œæ–¹æ¡ˆæœç´¢ç©ºé—´ï¼Œè®¾è®¡äº†ä¸€ä¸ªä¸“é—¨çš„æ¨¡æ‹Ÿå™¨æ¥è¯„ä¼°è¦è®­ç»ƒçš„ç¥ç»ç½‘ç»œçš„æ€§èƒ½æƒ…å†µï¼Œç„¶ååœ¨è¿™ä¸ªæœç´¢ç©ºé—´é‡Œé¢æ‰¾åˆ°æœ€ä½³çš„å¹¶è¡Œæ–¹æ¡ˆã€‚å¬ä¸Šå»æœ‰ç‚¹ç„ï¼Œä¸è¿‡æ‘˜è¦ä¸­è¯´å¯ä»¥è¾¾åˆ°æ¯” State-of-the-Art è¿˜è¦å¤§ 3.8 å€çš„ååé‡ï¼Œè¿˜æ˜¯å¾ˆå‰å®³çš„ã€‚

------

Introduction éƒ¨åˆ†æäº†ä¸‹ DNN å¹¶è¡Œçš„å¤§èƒŒæ™¯ï¼Œç›®å‰å¸‚é¢ä¸Šå¸¸è§çš„æ¡†æ¶ä¸­éƒ½åªæ˜¯æä¾›äº†ä¸€äº›ç®€å•çš„å¹¶è¡Œæ–¹æ¡ˆï¼Œè¦è¾¾åˆ°ç†æƒ³çš„æ€§èƒ½é€šå¸¸éœ€è¦ç ”ç©¶è€…è‡ªå·±å»æ ¹æ®ç½‘ç»œçš„ç‰¹æ€§æ‰‹å·¥è°ƒæ•´ã€‚ä¸¾ä¾‹æ¥è¯´ Google 14 å¹´æœ‰ä¸ªæŠŠå‰åŠéƒ¨åˆ†çš„å·ç§¯ç”¨æ•°æ®å¹¶è¡Œï¼Œæœ€åçš„å…¨è¿æ¥æ”¹ç”¨æ¨¡å‹å¹¶è¡Œçš„æ–¹æ¡ˆï¼Œä»¥åŠ Google å¯¹è‡ªå·±æœºå™¨ç¿»è¯‘æ¨¡å‹åšçš„ä¸€äº›å¹¶è¡Œæ–¹æ¡ˆè®¾è®¡ã€‚å¦å¤–è¿˜æœ‰ä¾é å¼ºåŒ–å­¦ä¹ ç­‰æ–¹æ³•å»æ‰¾åˆ°æœ€ä½³çš„å¹¶è¡Œæ–¹æ¡ˆï¼ˆä¾‹å¦‚ Google çš„æ¨¡å‹å¹¶è¡Œè®¾å¤‡åˆ†é…å·¥ä½œï¼Œä»¥åŠè¿™é‡Œå¼•ç”¨äº†å¦å¤–ä¸€ä¸ªä»–ä»¬è‡ªå·±çš„å·¥ä½œï¼‰ã€‚

Google å¯¹æ¨¡å‹å¹¶è¡Œåšçš„å¼ºåŒ–å­¦ä¹ æ¯æ¬¡æ˜¯è¯•è·‘ä¸€éå¾—åˆ°å®é™…æ‰§è¡Œæ—¶é—´æ¥ä½œä¸ºä¸€ç§æ–¹æ¡ˆçš„ç»“æœï¼ˆå¸¸è§„æ“ä½œæ²¡æ¯›ç—…ï¼‰ï¼Œå› æ­¤å½“æœç´¢ç©ºé—´å¾ˆå¤§çš„æ—¶å€™å°±ä¸å¯é¿å…åœ°éœ€è¦èŠ±è´¹å¾ˆé•¿æ—¶é—´ã€‚é‚£è¿™ç¯‡æ–‡ç« çš„å…³é”®å°±åœ¨äºä»–ä»¬æ¨¡æ‹Ÿå™¨çš„è®¾è®¡ï¼Œç”¨æ¨¡æ‹Ÿå™¨ç›´æ¥è¯„ä¼°ç½‘ç»œçš„æ‰§è¡Œæ€§èƒ½è‡ªç„¶æ˜¯æ˜¯è¦æ¯”å®è·‘å¿«å¾ˆå¤šçš„ï¼ˆè¿™é‡Œè¯´å¿«äº†å¥½å‡ ä¸ªæ•°é‡çº§ï¼‰ï¼Œé—®é¢˜æ˜¯è¿™æ ·è¯„ä¼°å‡ºæ¥çš„ç»“æœæ˜¯å¦å¯é ï¼Ÿ

æ–‡ç« ä¸»è¦çš„ä¾æ®æœ‰ä¸¤ä¸ªï¼š

1. å¤§å¤šæ•°ç¥ç»ç½‘ç»œçš„æ¨¡å‹éƒ½æ˜¯ç”±å¸¸è§çš„ç»“æ„ç»„æˆï¼Œåªä¼šæœ‰å¾ˆå°‘é‡çš„ç‰¹æ®Šç½‘ç»œå±‚ï¼›
2. ç¥ç»ç½‘ç»œæ¯ä¸€å±‚çš„è¿è¡Œæ—¶é—´åŸºæœ¬ä¸Šåªä¸ç¡¬ä»¶æœ¬èº«ç›¸å…³ï¼Œè¾“å…¥è§„æ¨¡å›ºå®šä¹‹ååŸºæœ¬ä¸ä¼šå—å…¶ä»–å› ç´ å½±å“ã€‚

å› æ­¤æ–‡ç« ä¸­çš„æ¨¡æ‹Ÿå™¨çš„åšæ³•æ˜¯é¢„å…ˆå¾—åˆ°ä¸åŒè¾“å…¥è§„æ¨¡ä¸‹å„ä¸ªç½‘ç»œå±‚çš„æ‰§è¡Œæ—¶é—´ï¼Œä¹‹åå†ç”¨è¿™äº›æ•°æ®æ¥è¯„ä¼°ç½‘ç»œæ¨¡å‹çš„æ‰§è¡Œæ—¶é—´ã€‚ç›¸æ¯” Google çš„åšæ³•ï¼Œè¿™æ ·å¯ä»¥æ›´å¿«ï¼Œè€Œä¸”é€Ÿåº¦å¿«äº†ä»¥åæ•´ä½“çš„æ–¹æ¡ˆæœç´¢è¿‡ç¨‹å¯¹ç¡¬ä»¶èµ„æºçš„éœ€æ±‚ä¹Ÿå°±å°‘çš„å¤šäº†ï¼ˆGoogle ç”¨äº† 160 ä¸ª 4 GPU èŠ‚ç‚¹ï¼Œæœ¬æ–‡åªéœ€è¦å•ä¸ªèŠ‚ç‚¹ï¼‰ã€‚åé¢å¯¹ä¼˜åŒ–æ–¹æ¡ˆçš„æœç´¢é‡‡ç”¨çš„æ˜¯é©¬å°”ç§‘å¤«é“¾è’™ç‰¹å¡æ´›çš„æ–¹æ³•ï¼Œç„¶åå„ç§æµ‹è¯•çš„æ•ˆæœéƒ½å¾ˆä¸é”™ã€‚

ç›¸å…³å·¥ä½œçš„å¯¹æ¯”é‡Œé¢è¿˜æœ‰æåˆ°ç”¨ç½‘ç»œæµæ¥ä¼˜åŒ–ä»»åŠ¡è°ƒåº¦çš„ï¼ˆ666666ï¼‰ã€‚

------

# Large Scale Neural Network Training

è¿™ä¸ªåˆ†ç±»ä¸‹é¢ä¸»è¦æ˜¯å®é™…åº”ç”¨å±‚é¢çš„å·¥ä½œã€‚

## 2013 ICASSP - Building High-level Features Using Large Scale Unsupervised Learning

è°·æ­Œåšçš„æ— ç›‘ç£å­¦ä¹ å›¾åƒåˆ†ç±»çš„å·¥ä½œã€‚

åœ¨ä¸€ä¸ªè¶…è¿‡ 1000 ä¸ªèŠ‚ç‚¹çš„é›†ç¾¤ä¸Šç”¨äº†æ¨¡å‹å¹¶è¡Œå’Œå¼‚æ­¥ SGDã€‚

æ–‡ä¸­çš„ç½‘ç»œå«ç¨€ç–æ·±åº¦è‡ªç¼–ç å™¨ï¼ˆSparse Deep Autoencoderï¼‰ï¼ŒåŸºæœ¬ä¸Šè·Ÿç°åœ¨çš„ DNN å·®ä¸å¤šï¼Œåº”è¯¥æ˜¯å½“æ—¶æ·±åº¦å­¦ä¹ è¿™ä¸ªæ¦‚å¿µè¿˜æ²¡æœ‰å®Œå…¨å®šå‹ã€‚

å®ç°æ–¹é¢æ²¡æœ‰å…·ä½“å†™çš„å¾ˆæ¸…æ¥šï¼Œä¸»è¦å‚çœ‹å‰é¢[12å¹´NIPSçš„é‚£ç¯‡å·¥ä½œå§](http://jcf94.com/2017/12/20/2017-12-20-distributeddl/#2012-NIPS-Large-Scale-Distributed-Deep-Networks)ã€‚

------

> è¿™é‡Œçš„å‡ ç¯‡å„å®¶æ‹¼ ImageNet è®­ç»ƒé€Ÿåº¦çš„ç¬”è®°æ•´ç†åˆ°æ–°å¸–é‡Œäº†ï¼š
>
> - [ã€Faster and Faster â€“ ImageNetã€‘](http://jcf94.com/2018/11/26/2018-11-26-fasterimagenet/)